# TOKEN: GITHUB_TOKEN (default with explicit permissions)
# PERMISSIONS: contents:read, pull-requests:write
# PURPOSE: Continuous integration and testing for DevOnboarder
# COMPLIANCE: Universal Workflow Permissions Policy + No Default Token Policy v1.0
# SCOPE: Code quality validation and test execution

# ---
# codex-agent:
#   name: Agent.CI
#   role: Runs tests and linting for all pushes and pull requests
#   scope: .github/workflows/ci.yml
#   triggers: Push and pull_request events
#   output: Build artifacts and coverage reports
#   token: CI_ISSUE_AUTOMATION_TOKEN -> CI_BOT_TOKEN -> GITHUB_TOKEN (fallback chain)
#   permissions: See .codex/bot-permissions.yaml for token capabilities
# ---
name: CI

env:
    CACHE_BUSTER: v-node22-py312

on:
    push:
    pull_request:

concurrency:
    group: ${{ github.workflow }}-${{ github.ref }}
    cancel-in-progress: true

permissions:
    contents: read          # Base access (write only when needed)
    issues: write          # CI_ISSUE_AUTOMATION_TOKEN authorized
    pull-requests: write   # CI_ISSUE_AUTOMATION_TOKEN authorized
    actions: read          # For workflow monitoring

jobs:
    validate-yaml:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v3
            - uses: ibiqlik/action-yamllint@v3
              with:
                  file_or_dir: ".github/workflows/**/*.yml"
                  config_file: .github/.yamllint-config
    filter:
        needs: validate-yaml
        runs-on: ubuntu-latest
        outputs:
            code: ${{ steps.filter.outputs.code }}
            docs: ${{ steps.filter.outputs.docs }}
        steps:
            - uses: actions/checkout@v3
              with:
                  fetch-depth: 0
            - name: Filter paths
              id: filter
              uses: dorny/paths-filter@v2
              with:
                  filters: |
                      code:
                          - 'src/**'
                          - 'bot/**'
                          - 'frontend/**'
                          - 'auth/**'
                          - 'tests/**'
                          - 'scripts/**'
                          - 'config/**'
                          - '.github/workflows/**'
                          - 'pyproject.toml'
                          - 'package*.json'
                          - '.tool-versions'
                          - 'docker-compose*.yaml'
                          - '.env*'
                          - 'Makefile'
                          - 'plugins/**'
                      docs:
                          - 'docs/**'
                          - '**/*.md'
                          - '.github/copilot-instructions.md'
    test:
        needs: filter
        if: |
            github.event_name == 'pull_request' ||
            (github.event_name == 'push' &&
             !contains(join(github.event.head_commit.message), '[no-ci]'))
        runs-on: ubuntu-latest
        environment: ci
        strategy:
            matrix:
                python-version: ["3.12"]
                node-version: ["22"]
        timeout-minutes: 60
        env:
            VALE_VERSION: 3.12.0

        steps:
            - uses: actions/checkout@v3
              with:
                  fetch-depth: 0
                  ref: ${{ github.head_ref }}
            - name: Install shellcheck
              run: pip install shellcheck-py
            - name: Lint shell scripts
              run: shellcheck --severity=warning scripts/*.sh
            - name: Lint commit messages
              run: bash scripts/check_commit_messages.sh
            - name: Install the gh cli
              uses: sersoft-gmbh/setup-gh-cli-action@v2
              with:
                  version: stable
            - name: Show gh version
              run: which gh && gh --version
            - name: Verify gh version
              run: |
                  ver=$(gh --version | head -n1 | awk '{print $3}')
                  major=${ver%%.*}
                  if [ "$major" -lt 2 ]; then
                  echo "::error::GitHub CLI v2 or higher required" >&2
                  exit 1
                  fi
            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: ${{ matrix.python-version }}
            - name: Set up Node
              uses: actions/setup-node@v4
              with:
                  node-version: ${{ matrix.node-version }}
            - name: Verify language versions
              run: bash scripts/check_versions.sh
            - name: Cache pip downloads
              uses: actions/cache@v3
              with:
                  path: ~/.cache/pip
                  key: ${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
                  restore-keys: |
                      ${{ runner.os }}-py${{ matrix.python-version }}-
            - name: Cache frontend node modules
              uses: actions/cache@v3
              with:
                  path: frontend/node_modules
                  key: ${{ runner.os }}-node${{ matrix.node-version }}-frontend-${{ hashFiles('frontend/package-lock.json') }}
                  restore-keys: |
                      ${{ runner.os }}-node${{ matrix.node-version }}-frontend-
            - name: Cache bot node modules
              uses: actions/cache@v3
              with:
                  path: bot/node_modules
                  key: ${{ runner.os }}-node${{ matrix.node-version }}-bot-${{ hashFiles('bot/package-lock.json') }}
                  restore-keys: |
                      ${{ runner.os }}-node${{ matrix.node-version }}-bot-
            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v3
            - name: Prepare CI log directory
              run: mkdir -p logs
            - name: Create virtual environment
              run: |
                  python -m venv .venv
                  source .venv/bin/activate
                  printf "VIRTUAL_ENV=%s\n" "$VIRTUAL_ENV" >> $GITHUB_ENV
                  printf "%s/bin\n" "$VIRTUAL_ENV" >> $GITHUB_PATH
            - name: Install dev dependencies
              run: |
                  source .venv/bin/activate
                  pip install .[test] 2>&1 | tee logs/pip-install.log || {
                      echo "Pip install failed. See docs/offline-setup.md for offline instructions." >&2
                      exit 1
                  }
            - name: Check Python dependencies
              run: |
                  source .venv/bin/activate
                  pip check
            - name: Python dependency audit
              run: |
                  source .venv/bin/activate
                  if ! pip-audit; then
                    code=$?
                    if [ "$code" -eq 1 ]; then
                      exit 1
                    else
                      echo "pip-audit failed. See docs/offline-setup.md for offline instructions." >&2
                    fi
                  fi
            - name: Install yamllint
              run: |
                  source .venv/bin/activate
                  pip install yamllint
            - name: Lint and validate bot permissions
              run: bash scripts/validate-bot-permissions.sh
            - name: Run Ruff Format
              run: |
                  source .venv/bin/activate
                  python -m ruff format --check .
            - name: Regenerate env docs
              run: |
                  source .venv/bin/activate
                  python scripts/regenerate_env_docs.py
            - name: Validate env docs
              run: |
                  source .venv/bin/activate
                  python scripts/check_env_docs.py
            - name: Validate Codex Agents
              run: |
                  source .venv/bin/activate
                  python scripts/validate_agents.py
            - name: Setup environment
              run: ./scripts/setup-env.sh
            - name: Install package
              run: |
                  source .venv/bin/activate
                  pip install -e .[test] 2>&1 | tee logs/pip-install-editable.log
            - name: Enforce Potato ignore policy
              run: bash scripts/check_potato_ignore.sh
            - name: Validate PR Summary
              if: github.event_name == 'pull_request'
              run: |
                  if [ ! -f "PR_SUMMARY.md" ]; then
                      echo "::error::PR_SUMMARY.md is required for all pull requests"
                      echo "TIP: Use the template: .github/PR_SUMMARY_TEMPLATE.md"
                      echo "COPY: cp .github/PR_SUMMARY_TEMPLATE.md PR_SUMMARY.md"
                      exit 1
                  fi

                  # Validate required sections and content
                  source .venv/bin/activate
                  python scripts/validate_pr_summary.py PR_SUMMARY.md
            - name: Quality Control Gate
              run: |
                  # Run comprehensive 95% QC validation
                  if [[ -x "./scripts/qc_pre_push.sh" ]]; then
                      echo "RUNNING: 95% Quality Control validation..."
                      ./scripts/qc_pre_push.sh
                  else
                      echo "Notice: QC script not found, skipping comprehensive validation"
                  fi
            - name: Generate OpenAPI spec
              run: |
                  source .venv/bin/activate
                  python scripts/generate_openapi.py
            - name: Check committed OpenAPI spec
              run: |
                  git diff --quiet src/devonboarder/openapi.json || {
                      echo "::error::openapi.json is outdated. Run 'make openapi'" \
                           " and commit the changes.";
                      exit 1;
                  }
            - name: Validate OpenAPI contract
              run: |
                  source .venv/bin/activate
                  python -c "
                  import json
                  from openapi_spec_validator import validate_spec

                  with open('src/devonboarder/openapi.json') as f:
                      spec = json.load(f)

                  try:
                      validate_spec(spec)
                      print('PASS: OpenAPI spec is valid')
                  except Exception as e:
                      print(f'FAIL: OpenAPI spec validation failed: {e}')
                      exit(1)
                  "
            - name: Alembic migration lint
              run: ./scripts/alembic_migration_check.sh
            - name: Doc coverage check
              run: |
                  source .venv/bin/activate
                  python scripts/check_docstrings.py src/devonboarder
            - name: Run linter
              run: |
                  source .venv/bin/activate
                  ruff check --output-format=github .
            - name: Run mypy
              run: |
                  source .venv/bin/activate
                  mypy --cache-dir=logs/.mypy_cache src/devonboarder
            - name: Install Vale
              run: |
                  # Download and install Vale 3.12.0 to /usr/local/bin
                  VALE_VERSION=3.12.0
                  VALE_URL="https://github.com/errata-ai/vale/releases/download/v${VALE_VERSION}/vale_${VALE_VERSION}_Linux_64-bit.tar.gz"
                  TMP_DIR=$(mktemp -d)
                  trap 'rm -rf "$TMP_DIR"' EXIT
                  curl -fsSL "$VALE_URL" | tar -xzC "$TMP_DIR"
                  sudo install -m 755 "$TMP_DIR/vale" /usr/local/bin/vale
                  # Verify installation
                  vale --version
            - name: Documentation style check
              run: ./scripts/check_docs.sh
            - name: Upload Vale results
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: vale-results
                  path: logs/vale-results.json
                  retention-days: 7
            - name: Generate secrets
              run: ./scripts/generate-secrets.sh
            - name: Audit environment variables
              run: |
                  mkdir -p logs
                  env -i PATH="$PATH" bash -c 'set -a; source .env.ci; set +a; JSON_OUTPUT=logs/env_audit.json bash scripts/audit_env_vars.sh' > logs/env_audit.log
                  cat logs/env_audit.log
                  cat logs/env_audit.json
                  missing=$(python -c 'import json,sys;print("".join(json.load(open("logs/env_audit.json")).get("missing", [])))')
                  extras=$(python -c 'import json,sys;d=json.load(open("logs/env_audit.json"));print("".join(e for e in d.get("extra", []) if e not in ("PATH","PWD","SHLVL","_")))')
                  if [ -n "$missing" ] || [ -n "$extras" ]; then
                      echo "::error::Environment variable mismatch detected"
                      exit 1
                  fi
            - name: Upload env audit
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: env-audit
                  path: |
                      logs/env_audit.log
                      logs/env_audit.json
                  retention-days: 7
            - name: Build containers
              run: docker compose -f docker-compose.ci.yaml --env-file .env.ci build 2>&1 | tee logs/docker-build.log
            - name: Scan images with Trivy
              env:
                  TRIVY_VERSION: 0.47.0
              run: bash scripts/trivy_scan.sh docker-compose.ci.yaml
            - name: Start docker compose
              run: docker compose -f docker-compose.ci.yaml --env-file .env.ci up -d
            - name: Verify compose services
              run: |
                  docker compose -f docker-compose.ci.yaml --env-file .env.ci ps
                  failed=$(docker compose -f docker-compose.ci.yaml --env-file .env.ci ps -q | xargs -r docker inspect -f '{{.State.Status}}' | grep -v running || true)
                  if [ -n "$failed" ]; then
                      docker compose logs
                      exit 1
                  fi
            - name: Wait for auth service
              run: bash scripts/wait_for_service.sh http://localhost:8002/health 30 2 auth
            - name: Run diagnostics
              run: |
                  mkdir -p logs
                  source .venv/bin/activate
                  python -m diagnostics > logs/diagnostics.log
            - name: Upload diagnostics
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: diagnostics
                  path: logs/diagnostics.log
                  retention-days: 7
            - name: Prepare test-results directory
              run: mkdir -p test-results logs
            - name: Run tests with coverage
              run: |
                  source .venv/bin/activate
                  COVERAGE_FILE=logs/.coverage pytest \
                      --cache-dir=logs/.pytest_cache \
                      --cov=src \
                      --cov-report=xml:logs/coverage.xml \
                      --cov-fail-under=95 \
                      --junitxml=test-results/pytest-results.xml \
                      2>&1 | tee logs/pytest.log
            - name: Upload pytest results
              if: always() && hashFiles('test-results/pytest-results.xml') != ''
              uses: actions/upload-artifact@v4
              with:
                  name: pytest-results
                  path: test-results/pytest-results.xml
                  retention-days: 7
            - name: Annotate pytest failures
              if: failure() && hashFiles('test-results/pytest-results.xml') != ''
              run: |
                  line=$(grep -n -m 1 '<failure' test-results/pytest-results.xml | cut -d: -f1)
                  echo "::error file=test-results/pytest-results.xml,line=${line}::Test failures detected"
            - name: Install frontend dependencies
              run: |
                  npm ci || {
                      echo "npm install failed. See docs/offline-setup.md for offline instructions." >&2
                      exit 1
                  }
              working-directory: frontend
            - name: Run frontend lint
              run: npm run lint
              working-directory: frontend
            - name: Run frontend tests with coverage
              run: npm test 2>&1 | tee vitest.log
              working-directory: frontend
            - name: Upload vitest log
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: vitest-log
                  path: frontend/vitest.log
                  retention-days: 7
            - name: Cache Playwright browsers
              uses: actions/cache@v3
              with:
                  path: ~/.cache/ms-playwright
                  key: ${{ runner.os }}-node${{ matrix.node-version }}-playwright-${{ hashFiles('frontend/package-lock.json') }}
                  restore-keys: |
                      ${{ runner.os }}-node${{ matrix.node-version }}-playwright-
            - name: Install Playwright browsers
              run: npx playwright install --with-deps
              working-directory: frontend
            - name: Run E2E tests
              run: npm run test:e2e 2>&1 | tee playwright.log
              working-directory: frontend
              env:
                  AUTH_URL: http://localhost:8002
            - name: Run performance tests
              run: npm run perf 2>&1 | tee lhci.log
              working-directory: frontend
            - name: Run accessibility tests
              run: npm run test:a11y 2>&1 | tee a11y.log
              working-directory: frontend
            - name: Upload playwright log
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: playwright-log
                  path: frontend/playwright.log
                  retention-days: 7
            - name: Upload accessibility log
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: a11y-log
                  path: frontend/a11y.log
                  retention-days: 7
            - name: Upload Lighthouse log
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: lighthouse-log
                  path: frontend/lhci.log
                  retention-days: 7
            - name: Upload Lighthouse report
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: lighthouse-report
                  path: frontend/lhci-report
                  retention-days: 7
            - name: Install bot dependencies
              run: |
                  npm ci || {
                      echo "npm install failed. See docs/offline-setup.md for offline instructions." >&2
                      exit 1
                  }
              working-directory: bot
            - name: Run bot lint
              run: npm run lint
              working-directory: bot
            - name: Run bot tests with coverage
              run: npm test 2>&1 | tee jest.log
              working-directory: bot
            - name: Upload jest log
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: jest-log
                  path: bot/jest.log
                  retention-days: 7
            - name: Generate coverage summary
              env:
                  GITHUB_SERVER_URL: ${{ github.server_url }}
                  GITHUB_REPOSITORY: ${{ github.repository }}
                  GITHUB_RUN_ID: ${{ github.run_id }}
              run: |
                  source .venv/bin/activate
                  python scripts/post_coverage_comment.py coverage-summary.md
                  bash scripts/append_coverage_summary.sh coverage-summary.md
            - name: Upload coverage summary
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: coverage-summary
                  path: coverage-summary.md
                  retention-days: 7
            - name: Upload coverage data
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: coverage-data
                  path: |
                      bot/coverage
                      frontend/coverage
                      logs/.coverage
                      logs/coverage.xml
                  retention-days: 7
            - name: Post coverage comment
              if: github.event_name == 'pull_request'
              run: |
                  gh_bin=$(which gh)
                  "$gh_bin" pr comment ${{ github.event.pull_request.number }} --body-file coverage-summary.md
              env:
                  GH_TOKEN: ${{ secrets.CI_ISSUE_AUTOMATION_TOKEN || secrets.CI_BOT_TOKEN || secrets.GITHUB_TOKEN }}
            - name: Update coverage badge
              run: |
                  source .venv/bin/activate
                  python scripts/update_coverage_badge.py coverage-summary.md coverage.svg
            - name: Commit coverage badge
              env:
                  # Use DevOnboarder CI token hierarchy: CI_ISSUE_AUTOMATION_TOKEN -> CI_BOT_TOKEN -> GITHUB_TOKEN
                  CI_BOT_TOKEN: ${{ secrets.CI_ISSUE_AUTOMATION_TOKEN || secrets.CI_BOT_TOKEN || secrets.GITHUB_TOKEN }}
                  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
              run: |
                  # Ensure we're in virtual environment context for any Python tools
                  source .venv/bin/activate

                  git config user.name "${{ github.actor }}"
                  git config user.email "${{ github.actor }}@users.noreply.github.com"

                  # Check if coverage badge file exists and has changes
                  if [ -f "coverage.svg" ]; then
                      git add coverage.svg

                      # Only commit if there are changes
                      if git diff --staged --quiet; then
                          echo "No changes to coverage badge"
                      else
                          git commit -m "CHORE(ci): update coverage badge"
                          # Try CI token first, fallback to GITHUB_TOKEN with proper authentication
                          if [ -n "$CI_BOT_TOKEN" ] && [ "$CI_BOT_TOKEN" != "$GITHUB_TOKEN" ]; then
                              echo "Attempting push with CI_BOT_TOKEN..."
                              git push https://$CI_BOT_TOKEN@github.com/${{ github.repository }}.git HEAD:${{ github.ref }} || {
                                  echo "CI_BOT_TOKEN failed, falling back to GITHUB_TOKEN..."
                                  git push https://$GITHUB_TOKEN@github.com/${{ github.repository }}.git HEAD:${{ github.ref }} || {
                                      echo "FAIL: All git push attempts failed - coverage badge will be uploaded as artifact"
                                      exit 1  # Trigger failure condition for artifact upload
                                  }
                              }
                          else
                              echo "Using GITHUB_TOKEN for push..."
                              git push https://$GITHUB_TOKEN@github.com/${{ github.repository }}.git HEAD:${{ github.ref }} || {
                                  echo "FAIL: GITHUB_TOKEN push failed - coverage badge will be uploaded as artifact"
                                  exit 1  # Trigger failure condition for artifact upload
                              }
                          fi
                      fi
                  else
                      echo "Coverage badge file not found"
                  fi

            # Upload coverage badge as artifact if git push failed
            - name: Upload coverage badge as artifact (fallback)
              if: failure()
              uses: actions/upload-artifact@v4
              with:
                  name: coverage-badge-fallback
                  path: coverage.svg
                  retention-days: 30
            - name: Clean test artifacts
              if: always()
              run: bash scripts/clean_pytest_artifacts.sh
            - name: Post-success log cleanup
              if: success()
              run: |
                  echo "CI completed successfully - smart cleaning temporary artifacts"
                  bash scripts/manage_logs.sh smart-clean
                  echo "Complete: Temporary artifacts cleaned, important logs preserved for next run"

            - name: Wait for auth service
              run: bash scripts/wait_for_service.sh http://localhost:8002/health 30 2 auth
            - name: Check CORS & security headers
              run: ./scripts/check_headers.py
              env:
                  CHECK_HEADERS_URL: http://localhost:8002/api/user
            - name: Run security audit
              run: bash scripts/security_audit.sh
            - name: Bandit Security Scan
              run: bandit -r src -ll
            - name: NPM Audit (high severity)
              run: npm audit --audit-level=high
              working-directory: frontend
            - name: NPM Audit (bot)
              run: npm audit --audit-level=high
              working-directory: bot
            - name: Stop docker compose
              if: always()
              run: |
                  if [ -f .env.ci ]; then
                      docker compose -f docker-compose.ci.yaml --env-file .env.ci down
                  else
                      docker compose -f docker-compose.ci.yaml down
                  fi
            - name: Label Codex PR
              if: github.actor == 'codex[bot]'
              run: |
                  gh_bin=$(which gh)
                  if ! "$gh_bin" api user >/dev/null 2>&1; then
                      echo "::warning::GitHub CLI authentication failed. Skipping PR labeling."
                      exit 0
                  fi
                  if ! "$gh_bin" pr edit ${{ github.event.pull_request.number }} --add-label "Codex"; then
                      echo "::warning::Failed to add label to PR ${{ github.event.pull_request.number }}"
                  fi
              env:
                  GH_TOKEN: ${{ secrets.CI_ISSUE_AUTOMATION_TOKEN || secrets.CI_BOT_TOKEN || secrets.GITHUB_TOKEN }}
            - name: Summarize CI failures
              if: always()
              run: |
                  # Ensure virtual environment exists before activating
                  if [ ! -d ".venv" ]; then
                      echo "Virtual environment not found, creating minimal environment..."
                      python -m venv .venv
                      source .venv/bin/activate
                      # Install minimal dependencies if needed
                      pip install --quiet --no-deps pathlib || echo "Failed to install pathlib, continuing..."
                  else
                      source .venv/bin/activate
                  fi
                  python scripts/summarize_ci_failures.py
            - name: Run CI failure diagnoser
              if: always()
              run: |
                  # Ensure virtual environment exists before activating
                  if [ ! -d ".venv" ]; then
                      echo "Virtual environment not found, creating minimal environment..."
                      python -m venv .venv
                      source .venv/bin/activate
                      # Install minimal dependencies needed for diagnoser
                      pip install --quiet --no-deps pathlib || echo "Failed to install pathlib, continuing..."
                  else
                      source .venv/bin/activate
                  fi

                  # Create audit.md even if diagnoser fails
                  if python scripts/ci_failure_diagnoser.py ${{ runner.temp }}/_github_workflow/*/job.log > audit.md 2>&1; then
                      echo "CI failure diagnoser completed successfully"
                  else
                      echo "# CI Failure Analysis" > audit.md
                      echo "" >> audit.md
                      echo "CI failure diagnoser encountered an issue:" >> audit.md
                      echo "- Log files may not be available at expected location" >> audit.md
                      echo "- Job logs: \`${{ runner.temp }}/_github_workflow/*/job.log\`" >> audit.md
                      echo "" >> audit.md
                      echo "Please check the workflow logs for detailed error information." >> audit.md
                  fi
                  # Ensure audit.md exists and has content
                  if [ ! -f audit.md ] || [ ! -s audit.md ]; then
                      echo "# CI Status" > audit.md
                      echo "No failure patterns detected in available logs." >> audit.md
                  fi
            - name: Download previous CI failure issue
              if: always()
              run: bash scripts/download_ci_failure_issue.sh
              env:
                  GH_TOKEN: ${{ secrets.CI_ISSUE_AUTOMATION_TOKEN || secrets.CI_BOT_TOKEN || secrets.GITHUB_TOKEN }}
            - name: Create or update CI failure issue
              if: always() && github.event_name == 'pull_request'
              id: ci_failure
              run: |
                  set -euo pipefail
                  printf '\n<!-- sha: %s -->\n' "$GITHUB_SHA" >> summary.md

                  # Ensure audit.md exists before trying to read it
                  if [ -f audit.md ]; then
                      cat audit.md >> summary.md
                  else
                      echo "# CI Analysis" >> summary.md
                      echo "Audit file not available." >> summary.md
                  fi

                  gh_bin=$(which gh)
                  "$gh_bin" auth status 2>&1 | tee -a gh_cli.log

                  # Check if we have sufficient permissions
                  if ! gh_bin_check=$("$gh_bin" api user 2>&1); then
                      echo "::warning::GitHub CLI authentication failed. Skipping issue operations."
                      echo "Auth check output:" | tee -a gh_cli.log
                      printf "%s\n" "$gh_bin_check" | tee -a gh_cli.log
                      exit 0
                  fi

                  ISSUE_FILE=ci_failure_issue.txt
                  ISSUE_TITLE="CI Failure: PR #${{ github.event.pull_request.number }}"
                  if [ -f "$ISSUE_FILE" ]; then
                      ISSUE=$(cat "$ISSUE_FILE")
                      echo "Using saved issue number:" | tee -a gh_cli.log
                      printf "%s\n" "$ISSUE" | tee -a gh_cli.log
                      if ! "$gh_bin" issue comment "$ISSUE" --body-file summary.md 2>&1 | tee -a gh_cli.log; then
                          echo "Failed to comment on issue. Continuing without issue update." | tee -a gh_cli.log
                          echo "::warning::Failed to comment on issue ${ISSUE}. Continuing without issue update."
                      fi
                  else
                      echo "Searching for existing issue" | tee -a gh_cli.log
                      if search_output=$("$gh_bin" issue list --label ci-failure --state open --search "$ISSUE_TITLE" 2>&1 | tee -a gh_cli.log); then
                          ISSUE=$(echo "$search_output" | awk 'NR==1 {print $1}')
                          if [ -n "$ISSUE" ]; then
                              if ! "$gh_bin" issue comment "$ISSUE" --body-file summary.md 2>&1 | tee -a gh_cli.log; then
                                  echo "Failed to comment on existing issue" | tee -a gh_cli.log
                                  echo "::warning::Failed to comment on existing issue ${ISSUE}"
                              fi
                          else
                              if ISSUE_URL=$("$gh_bin" issue create --title "$ISSUE_TITLE" --body-file summary.md --label ci-failure 2>&1 | tee -a gh_cli.log); then
                                  ISSUE=$(echo "$ISSUE_URL" | grep -oE '[0-9]+$')
                              else
                                  echo "::warning::Failed to create new issue. Continuing without issue creation."
                                  ISSUE=""
                              fi
                          fi
                      else
                          echo "::warning::Failed to search for issues. Continuing without issue operations."
                          ISSUE=""
                      fi
                  fi
                  echo "issue-number=${ISSUE:-none}" >> "$GITHUB_OUTPUT"
              env:
                  GH_TOKEN: ${{ secrets.CI_ISSUE_AUTOMATION_TOKEN || secrets.CI_BOT_TOKEN || secrets.GITHUB_TOKEN }}
            - name: Save CI failure issue number
              if: failure() && github.event_name == 'pull_request'
              run: echo "${{ steps.ci_failure.outputs.issue-number }}" > ci_failure_issue.txt
            - name: Upload CI failure issue number
              if: failure() && github.event_name == 'pull_request'
              uses: actions/upload-artifact@v4
              with:
                  name: ci-failure-issue
                  path: ci_failure_issue.txt
                  retention-days: 7
            - name: Close CI failure issue
              if: success()
              run: |
                  gh_bin=$(which gh)

                  # Check if we have sufficient permissions
                  if ! "$gh_bin" api user >/dev/null 2>&1; then
                      echo "::warning::GitHub CLI authentication failed. Skipping issue closure."
                      exit 0
                  fi

                  if ISSUES=$("$gh_bin" issue list --label ci-failure --state open 2>&1 | tee -a gh_cli.log | awk '{print $1}'); then
                      for ISSUE in $ISSUES; do
                        if [ -n "$ISSUE" ] && [ "$ISSUE" != "#" ]; then
                            if ! "$gh_bin" issue comment "$ISSUE" --body "CI run ${{ github.run_id }} passed. Closing." 2>&1 | tee -a gh_cli.log; then
                                echo "Failed to comment on issue during closure" | tee -a gh_cli.log
                                echo "::warning::Failed to comment on issue ${ISSUE} during closure"
                            fi
                            if ! "$gh_bin" issue close "$ISSUE" 2>&1 | tee -a gh_cli.log; then
                                echo "Failed to close issue" | tee -a gh_cli.log
                                echo "::warning::Failed to close issue ${ISSUE}"
                            fi
                        fi
                      done
                  else
                      echo "::warning::Failed to list issues for closure"
                  fi
              env:
                  GH_TOKEN: ${{ secrets.CI_ISSUE_AUTOMATION_TOKEN || secrets.CI_BOT_TOKEN || secrets.GITHUB_TOKEN }}
            - name: Prepare CI log artifacts
              if: always()
              run: |
                  mkdir -p logs
                  mv -f gh_cli.log logs/ 2>/dev/null || true
                  mv -f audit.md logs/ 2>/dev/null || true
            - name: Upload CI logs
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: ci-logs
                  path: |
                      logs
                      ${{ runner.temp }}/_github_workflow/*/job.log
            - name: Root Artifact Guard
              if: always()
              run: bash scripts/enforce_output_location.sh

# PRODUCTION HARDENING COMPLETE
# This workflow meets DevOnboarder Universal Workflow Permissions Policy
# Token usage aligns with No Default Token Policy v1.0
# Required status checks documented in docs/ci/required-checks.md
# Skip behavior validated for conditional jobs compatibility
